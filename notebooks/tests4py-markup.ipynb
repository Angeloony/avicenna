{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1a4c68-2925-4e3c-8b35-739ac327eab7",
   "metadata": {},
   "source": [
    "# Tests4Py Benchmark: MarkUp\n",
    "This notebook handles benchmark tests for MarkUp in the Tests4Py framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39269d8-0cae-4628-83fd-8829da6002c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress logging for the notebook; uncomment the last line to disable Avicenna logs\n",
    "import logging\n",
    "\n",
    "# This will disable all logging messages\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321afbe-9552-472c-852a-27ea9e937efe",
   "metadata": {},
   "source": [
    "### Build Program from Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7498b12b-61ca-46a8-a056-7f76ab73a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests4py.api.logging import deactivate\n",
    "deactivate()\n",
    "\n",
    "from debugging_benchmark.tests4py_benchmark.repository import MarkUpBenchmarkRepository\n",
    "\n",
    "# Initialize the benchmark repository and select the first program\n",
    "repository = MarkUpBenchmarkRepository()\n",
    "programs = repository.build()\n",
    "program = programs[0]  # Assuming there is only one MarkUp Subject; we use markup_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46003c",
   "metadata": {},
   "source": [
    "### Initialize Diagnostic System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db3fee",
   "metadata": {},
   "source": [
    "Initialize the `Avicenna` diagnostic system with specific parameters including minimum recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a8ba40-ccab-4d8d-8e22-5922eb349d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Avicenna instance with configurations for diagnosis\n",
    "from avicenna.avicenna import Avicenna\n",
    "\n",
    "# Convert program to dictionary format for Avicenna initialization\n",
    "param = program.to_dict()\n",
    "\n",
    "# Initialize Avicenna with a minimum recall configuration\n",
    "avicenna = Avicenna(\n",
    "    **param,\n",
    "    min_recall=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5503b3-bc26-4fe5-af1b-ad14b527e8bc",
   "metadata": {},
   "source": [
    "### Diagnosis Execution and Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63f436a-9ae6-48d2-b130-32c871ea385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis complete.\n"
     ]
    }
   ],
   "source": [
    "# Perform the diagnosis using Avicenna and store the results\n",
    "from typing import Tuple\n",
    "from isla.language import Formula\n",
    "\n",
    "try:\n",
    "    diagnosis: Tuple[Formula, float, float] = avicenna.explain()\n",
    "    print(\"Diagnosis complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during diagnosis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caca1a0b-958c-4d56-8c03-6035e884496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avicenna determined the following constraints to describe the failure circumstances:\n",
      "\n",
      "exists <char> elem in start:\n",
      "  (= elem \"\\\"\")\n",
      "Avicenna calculated a precision of 96.03% and a recall of 98.04%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from isla.language import ISLaUnparser\n",
    "\n",
    "print(f\"Avicenna determined the following constraints to describe the failure circumstances:\\n\")\n",
    "\n",
    "print(ISLaUnparser(diagnosis[0]).unparse())\n",
    "print(f\"Avicenna calculated a precision of {diagnosis[1]*100:.2f}% and a recall of {diagnosis[2]*100:.2f}%\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8eb4f-fb2f-4d40-ab0a-e2ef69832511",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e8dc7-f3fe-4c95-acfa-109250417b07",
   "metadata": {},
   "source": [
    "Generate test inputs using a grammar-based fuzzer, and classify these inputs as passing or failing based on the learned constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617e75cf-4e0b-407b-821a-b734fd508031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from debugging_framework.fuzzingbook.fuzzer import GrammarFuzzer\n",
    "from debugging_framework.input.input import Input, OracleResult\n",
    "\n",
    "def generate_inputs(grammar, num_inputs=1000):\n",
    "    fuzzer = GrammarFuzzer(grammar)\n",
    "    evaluation_data_set = set()\n",
    "\n",
    "    while len(evaluation_data_set) < num_inputs:\n",
    "        tree = fuzzer.fuzz()\n",
    "        evaluation_data_set.add(Input.from_str(grammar=grammar, input_string=tree))\n",
    "\n",
    "    return evaluation_data_set\n",
    "\n",
    "def classify_inputs(program, evaluation_data_set):\n",
    "    oracle = program.get_oracle()\n",
    "    failing, passing = set(), set()\n",
    "\n",
    "    for inp in evaluation_data_set:\n",
    "        oracle_result, exception = oracle(inp)\n",
    "        if oracle_result == OracleResult.FAILING:\n",
    "            failing.add(inp)\n",
    "        elif oracle_result == OracleResult.PASSING:\n",
    "            passing.add(inp)\n",
    "\n",
    "    return passing, failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98dbe4c2-4659-4edc-b9d3-1d6718fedb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000 unique inputs for evaluation.\n",
      "Generated 961 passing inputs for evaluation!\n",
      "Generated 39 failing inputs for evaluation!\n"
     ]
    }
   ],
   "source": [
    "grammar = program.get_grammar()\n",
    "evaluation_data_set = generate_inputs(grammar)\n",
    "passing, failing = classify_inputs(program, evaluation_data_set)\n",
    "\n",
    "print(f\"Generated {len(evaluation_data_set)} unique inputs for evaluation.\")\n",
    "print(f\"Generated {len(passing)} passing inputs for evaluation!\")\n",
    "print(f\"Generated {len(failing)} failing inputs for evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c9a35-2075-410b-b33c-5ef4cf85de24",
   "metadata": {},
   "source": [
    "Calculate and display the precision and recall for the diagnostic results based on the test evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f593b943-20a9-4355-9b44-91f966673a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Diagnosis achieved a Precision of 92.00% a Recall of 58.97%\n"
     ]
    }
   ],
   "source": [
    "from isla.evaluator import evaluate\n",
    "\n",
    "# Calculate Precision and Recall\n",
    "tp = sum(bool(evaluate(diagnosis[0], inp.tree, grammar)) for inp in failing)\n",
    "fn = len(failing) - tp\n",
    "fp = sum(bool(evaluate(diagnosis[0], inp.tree, grammar)) for inp in passing)\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f\"The Diagnosis achieved a Precision of {precision*100:.2f}% \" +\n",
    "      f\"a Recall of {recall*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6ba8b-d2da-4cdb-9bf9-a474ed71d1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
