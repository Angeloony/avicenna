{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d6253a-03c4-4710-af76-aba079a85471",
   "metadata": {},
   "source": [
    "# SpecialCase Tests4Py: MarkUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de928b9-24cf-465e-9588-82afb246348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tests4py :: INFO     :: Loading projects\n"
     ]
    }
   ],
   "source": [
    "from tests4py.api.logging import deactivate\n",
    "deactivate()\n",
    "from debugging_benchmark.tests4py_benchmark.repository import MarkUpBenchmarkRepository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfb0453-9b54-40e4-aa9b-d5575e83d6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tests4PyBenchmarkProgram(markup_1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build programs \n",
    "programs = MarkUpBenchmarkRepository().build()\n",
    "program = programs[0]\n",
    "\n",
    "# There is only one MarkUp Subject\n",
    "program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49bfac39-39ca-44f4-a4f5-ac2c54119cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = program.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caca1a0b-958c-4d56-8c03-6035e884496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3405c2c2-3b5f-4830-89cd-5433c75ed246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avicenna.avicenna import Avicenna\n",
    "\n",
    "avicenna = Avicenna(\n",
    "    **program.to_dict(),\n",
    "    min_recall=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7d5fe-a578-435f-a538-02d4ec9345b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from isla.language import Formula\n",
    "\n",
    "diagnosis: Tuple[Formula, float, float] = avicenna.explain()\n",
    "# Avicenna returns a List of learned ISla Formula and the corresponding precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b114f2c-eac4-4b9f-b220-4c1780afc293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avicenna determined the following constraints to describe the failure circumstances:\n",
      "\n",
      "exists <char> elem in start:\n",
      "  (= elem \"\\\"\")\n",
      "Avicenna calculated a precision of 93.41% and a recall of 89.58%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from isla.language import ISLaUnparser\n",
    "\n",
    "print(f\"Avicenna determined the following constraints to describe the failure circumstances:\\n\")\n",
    "\n",
    "print(ISLaUnparser(diagnosis[0]).unparse())\n",
    "print(f\"Avicenna calculated a precision of {diagnosis[1]*100:.2f}% and a recall of {diagnosis[2]*100:.2f}%\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0263466-22cd-4688-a974-63efb1e21f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equivalent Representations:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEquivalent Representations:\")\n",
    "equivalent_representations = avicenna.get_equivalent_best_formulas()\n",
    "\n",
    "if equivalent_representations:\n",
    "    for diagnosis in equivalent_representations:\n",
    "        print(ISLaUnparser(diagnosis[0]).unparse())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95f3807-86a7-4f1c-a588-cf05a1bc4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation of the learned Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26616c88-8777-4dbe-a6af-7f5c400e51dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4308 inputs for evaluation!\n"
     ]
    }
   ],
   "source": [
    "from debugging_framework.fuzzingbook.fuzzer import GrammarFuzzer\n",
    "from debugging_framework.input.input import Input\n",
    "\n",
    "grammar = program.get_grammar()\n",
    "\n",
    "evaluation_data_set = set()\n",
    "fuzzer = GrammarFuzzer(grammar)\n",
    "\n",
    "for _ in range(10000):\n",
    "    tree = fuzzer.fuzz()\n",
    "    evaluation_data_set.add(Input.from_str(grammar=grammar, input_string=tree))\n",
    "\n",
    "print(f\"Generated {len(evaluation_data_set)} inputs for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f587f66b-087a-4936-a767-e03881ceef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4098 passing inputs for evaluation!\n",
      "Generated 210 passing inputs for evaluation!\n"
     ]
    }
   ],
   "source": [
    "from debugging_framework.input.input import OracleResult\n",
    "\n",
    "oracle = program.get_oracle()\n",
    "failing = set()\n",
    "passing = set()\n",
    "\n",
    "for inp in evaluation_data_set:\n",
    "    oracle_result, exception = oracle(inp)\n",
    "\n",
    "    if oracle_result == OracleResult.FAILING:\n",
    "        failing.add(inp)\n",
    "    elif oracle_result == OracleResult.PASSING:\n",
    "        passing.add(inp)\n",
    "\n",
    "print(f\"Generated {len(passing)} passing inputs for evaluation!\")\n",
    "print(f\"Generated {len(failing)} passing inputs for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "726c6c78-54f3-466a-8bd1-30ed4a5dd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isla.evaluator import evaluate\n",
    "\n",
    "eval_results_passing = []\n",
    "for inp in list(passing):\n",
    "    eval_results_passing.append(bool(evaluate(diagnosis[0], inp.tree, grammar)))\n",
    "\n",
    "eval_results_failing = []\n",
    "for inp in list(failing):\n",
    "    eval_results_failing.append(bool(evaluate(diagnosis[0], inp.tree, grammar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27c1ce89-a30e-4d8c-89e1-330d4851f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Diagnosis achieved a Precision of 85.84% and a Recall of 46.19%\n"
     ]
    }
   ],
   "source": [
    "tp = sum(int(entry) for entry in eval_results_failing)\n",
    "fn = len(eval_results_failing) -tp\n",
    "fp = sum(int(entry) for entry in eval_results_passing)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(f\"The Diagnosis achieved a Precision of {precision*100:.2f}% and a Recall of {recall*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfa67460-98a9-4ff9-8b42-964a7b4d89ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Diagnosis achieved a Precision of 85.84% and a Recall of 46.19%\n"
     ]
    }
   ],
   "source": [
    "tp = sum(int(entry) for entry in list(eval_results_failing))\n",
    "fn = len(eval_results_failing) -tp\n",
    "fp = sum(int(entry) for entry in eval_results_passing)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(f\"The Diagnosis achieved a Precision of {precision*100:.2f}% and a Recall of {recall*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cec820-e497-4b75-83f7-9f8750acf2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
